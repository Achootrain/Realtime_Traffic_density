name: Build & Deploy to GHCR (K3s)

# ============================================
# Deployment uses AWS SSM (no SSH required).
# Required GitHub Secrets:
#   AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY  — IAM user with ssm:SendCommand + ssm:GetCommandInvocation
#   EC2_INSTANCE_ID  — e.g. i-0b5593095b09bbb82
#   GHCR_USERNAME, GHCR_TOKEN  — for imagePullSecrets
# ============================================

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      service:
        description: "Which service to deploy?"
        type: choice
        required: true
        default: kafka
        options:
          - kafka
          - spark

permissions:
  contents: read
  packages: write

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # 1. Lowercase repo owner
      - name: Lowercase Repo Owner
        run: |
          echo "REPO_OWNER=${GITHUB_REPOSITORY_OWNER,,}" >> ${GITHUB_ENV}

      # 2. Resolve build target
      - name: Resolve build target
        id: target
        shell: bash
        run: |
          set -e
          CHOSEN_SERVICE="${{ github.event.inputs.service }}"
          
          if [[ -z "$CHOSEN_SERVICE" ]]; then
            if git diff --name-only HEAD^ HEAD | grep -q "^spark/"; then
               CHOSEN_SERVICE="spark"
            elif git diff --name-only HEAD^ HEAD | grep -q "^kafka/"; then
               CHOSEN_SERVICE="kafka"
            else
               CHOSEN_SERVICE="kafka"
            fi
          fi
          
          echo "service=$CHOSEN_SERVICE" >> "$GITHUB_OUTPUT"

      # 3. Configure AWS credentials (for SSM)
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      # 4. Copy manifests to EC2 via SSM (tar → base64 → SSM → decode)
      - name: Upload manifests via SSM
        run: |
          # Package k8s manifests, init.sql, and clean.sh into a tarball
          tar czf /tmp/deploy-bundle.tar.gz k8s/*.yaml timescaledb/init.sql clean.sh

          # Base64 encode (SSM has 24KB command limit, tar is small enough)
          BUNDLE_B64=$(base64 -w0 /tmp/deploy-bundle.tar.gz)

          # Send via SSM
          COMMAND_ID=$(aws ssm send-command \
            --instance-ids "${{ secrets.EC2_INSTANCE_ID }}" \
            --document-name "AWS-RunShellScript" \
            --parameters "commands=[
              \"mkdir -p /home/ubuntu/k8s /home/ubuntu/timescaledb\",
              \"echo '$BUNDLE_B64' | base64 -d > /tmp/deploy-bundle.tar.gz\",
              \"cd /home/ubuntu && tar xzf /tmp/deploy-bundle.tar.gz\",
              \"chmod +x /home/ubuntu/clean.sh\",
              \"rm -f /tmp/deploy-bundle.tar.gz\"
            ]" \
            --timeout-seconds 60 \
            --query "Command.CommandId" --output text)

          # Wait for completion
          aws ssm wait command-executed \
            --command-id "$COMMAND_ID" \
            --instance-id "${{ secrets.EC2_INSTANCE_ID }}" || true

          STATUS=$(aws ssm get-command-invocation \
            --command-id "$COMMAND_ID" \
            --instance-id "${{ secrets.EC2_INSTANCE_ID }}" \
            --query "Status" --output text)

          if [[ "$STATUS" != "Success" ]]; then
            echo "SSM copy command failed with status: $STATUS"
            aws ssm get-command-invocation \
              --command-id "$COMMAND_ID" \
              --instance-id "${{ secrets.EC2_INSTANCE_ID }}" \
              --query "StandardErrorContent" --output text
            exit 1
          fi

          echo "Manifests uploaded successfully via SSM"

      # 5. Deploy on K3s via SSM
      - name: Deploy on K3s via SSM
        run: |
          COMMAND_ID=$(aws ssm send-command \
            --instance-ids "${{ secrets.EC2_INSTANCE_ID }}" \
            --document-name "AWS-RunShellScript" \
            --timeout-seconds 300 \
            --parameters "commands=[
              \"#!/bin/bash\",
              \"set -e\",
              \"export KUBECONFIG=/home/ubuntu/.kube/config\",
              \"export HOME=/home/ubuntu\",
              \"cd /home/ubuntu/k8s\",
              \"\",
              \"# Resolve EC2 public IP for Kafka advertised listener\",
              \"EC2_HOST=\\$(curl -s http://169.254.169.254/latest/meta-data/public-ipv4)\",
              \"sed -i \\\"s/IP_PLACEHOLDER/\\$EC2_HOST/g\\\" kafka.yaml || true\",
              \"\",
              \"# Setup Helm\",
              \"if ! command -v helm &> /dev/null; then curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash; fi\",
              \"helm repo add spark-operator https://kubeflow.github.io/spark-operator || true\",
              \"helm repo update\",
              \"\",
              \"# Create namespace\",
              \"kubectl create namespace traffic --dry-run=client -o yaml | kubectl apply -f -\",
              \"\",
              \"# Create GHCR imagePullSecret\",
              \"kubectl create secret docker-registry ghcr-secret --namespace traffic --docker-server=ghcr.io --docker-username='${{ secrets.GHCR_USERNAME }}' --docker-password='${{ secrets.GHCR_TOKEN }}' --docker-email=noreply@example.com --dry-run=client -o yaml | kubectl apply -f -\",
              \"\",
              \"# Create AWS credentials secret\",
              \"kubectl create secret generic aws-credentials --namespace traffic --from-literal=access_key_id='${{ secrets.AWS_ACCESS_KEY_ID }}' --from-literal=secret_access_key='${{ secrets.AWS_SECRET_ACCESS_KEY }}' --dry-run=client -o yaml | kubectl apply -f -\",
              \"\",
              \"# Install/Upgrade Spark Operator\",
              \"helm upgrade --install spark-operator-1 spark-operator/spark-operator --namespace traffic --set controller.namespaces={traffic} --set webhook.enable=true\",
              \"\",
              \"# Apply kustomize\",
              \"kubectl apply -k .\",
              \"\",
              \"# Init TimescaleDB\",
              \"kubectl wait --for=condition=ready pod/timescaledb-0 -n traffic --timeout=120s || true\",
              \"if [ -f /home/ubuntu/timescaledb/init.sql ]; then kubectl cp /home/ubuntu/timescaledb/init.sql traffic/timescaledb-0:/tmp/init.sql; kubectl exec timescaledb-0 -n traffic -- psql -U postgres -d traffic -f /tmp/init.sql || true; fi\",
              \"\",
              \"# Restart based on service\",
              \"SERVICE_NAME='${{ steps.target.outputs.service }}'\",
              \"if [ \\\"\\$SERVICE_NAME\\\" == \\\"kafka\\\" ]; then kubectl rollout restart statefulset/kafka -n traffic || true; kubectl rollout restart deployment/kafka-producer -n traffic || true; elif [ \\\"\\$SERVICE_NAME\\\" == \\\"spark\\\" ]; then kubectl delete sparkapplication spark-realtime-python -n traffic --ignore-not-found; kubectl delete sparkapplication spark-s3-glacier -n traffic --ignore-not-found; sleep 5; kubectl apply -f spark-realtime-app.yaml -n traffic; kubectl apply -f spark-s3-glacier-app.yaml -n traffic; fi\",
              \"\",
              \"echo 'Deploy complete!'\"
            ]" \
            --query "Command.CommandId" --output text)

          echo "SSM Command ID: $COMMAND_ID"

          # Wait for command to complete
          echo "Waiting for deployment to complete..."
          aws ssm wait command-executed \
            --command-id "$COMMAND_ID" \
            --instance-id "${{ secrets.EC2_INSTANCE_ID }}" || true

          # Get result
          RESULT=$(aws ssm get-command-invocation \
            --command-id "$COMMAND_ID" \
            --instance-id "${{ secrets.EC2_INSTANCE_ID }}")

          STATUS=$(echo "$RESULT" | jq -r '.Status')
          echo "Command Status: $STATUS"
          echo "--- STDOUT ---"
          echo "$RESULT" | jq -r '.StandardOutputContent'
          echo "--- STDERR ---"
          echo "$RESULT" | jq -r '.StandardErrorContent'

          if [[ "$STATUS" != "Success" ]]; then
            echo "Deployment failed!"
            exit 1
          fi

          echo "Deployment successful!"